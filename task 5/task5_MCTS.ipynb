{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seminar: Monte-carlo tree search\n",
    "\n",
    "In this seminar, we'll implement a vanilla MCTS planning and use it to solve some Gym envs.\n",
    "\n",
    "But before we do that, we first need to modify gym env to allow saving and loading game states to facilitate backtracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.core import Wrapper\n",
    "from pickle import dumps,loads\n",
    "from collections import namedtuple\n",
    "from copy import deepcopy\n",
    "import pygame\n",
    "import copy\n",
    "\n",
    "\n",
    "#a container for get_result function below. Works just like tuple, but prettier\n",
    "ActionResult = namedtuple(\"action_result\",(\"snapshot\",\"observation\",\"reward\",\"is_done\",\"info\"))\n",
    "    \n",
    "\n",
    "\n",
    "class WithSnapshots(Wrapper):\n",
    "    \"\"\"\n",
    "    Creates a wrapper that supports saving and loading environemnt states.\n",
    "    Required for planning algorithms.\n",
    "\n",
    "    This class will have access to the core environment as self.env, e.g.:\n",
    "    - self.env.reset()           #reset original env\n",
    "    - self.env.ale.cloneState()  #make snapshot for atari. load with .restoreState()\n",
    "    - ...\n",
    "\n",
    "    You can also use reset, step and render directly for convenience.\n",
    "    - s, r, done, _ = self.step(action)   #step, same as self.env.step(action)\n",
    "    - self.render(close=True)             #close window, same as self.env.render(close=True)\n",
    "    \"\"\"\n",
    "\n",
    "        \n",
    "    def get_snapshot(self):\n",
    "        \"\"\"\n",
    "        :returns: environment state that can be loaded with load_snapshot \n",
    "        Snapshots guarantee same env behaviour each time they are loaded.\n",
    "        \n",
    "        Warning! Snapshots can be arbitrary things (strings, integers, json, tuples)\n",
    "        Don't count on them being pickle strings when implementing MCTS.\n",
    "        \n",
    "        Developer Note: Make sure the object you return will not be affected by \n",
    "        anything that happens to the environment after it's saved.\n",
    "        You shouldn't, for example, return self.env. \n",
    "        In case of doubt, use pickle.dumps or deepcopy.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.close() #close popup windows since we can't pickle them\n",
    "        \n",
    "        x = copy(self.env)\n",
    "        \n",
    "        return dumps(PickleableSurface(self.env))\n",
    "    \n",
    "    def load_snapshot(self,snapshot):\n",
    "        \"\"\"\n",
    "        Loads snapshot as current env state.\n",
    "        Should not change snapshot inplace (in case of doubt, deepcopy).\n",
    "        \"\"\"\n",
    "        \n",
    "        assert not hasattr(self,\"_monitor\") or hasattr(self.env,\"_monitor\"), \"can't backtrack while recording\"\n",
    "\n",
    "        self.close() #close popup windows since we can't load into them\n",
    "        self.env = loads(snapshot)\n",
    "    \n",
    "    def get_result(self,snapshot,action):\n",
    "        \"\"\"\n",
    "        A convenience function that \n",
    "        - loads snapshot, \n",
    "        - commits action via self.step,\n",
    "        - and takes snapshot again :)\n",
    "        \n",
    "        :returns: next snapshot, next_observation, reward, is_done, info\n",
    "        \n",
    "        Basically it returns next snapshot and everything that env.step would have returned.\n",
    "        \"\"\"\n",
    "        state = self.load_snapshot(snapshot)\n",
    "        s, r, done, i = self.step(action)\n",
    "        nextsn = self.get_snapshot() \n",
    "        \n",
    "        return ActionResult(nextsn,    #fill in the variables\n",
    "                            s, \n",
    "                            r, done, i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try out snapshots (2 pts):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make env\n",
    "env = WithSnapshots(gym.make(\"CartPole-v0\", render_mode='rgb_array'))\n",
    "env.reset()\n",
    "\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_state:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(env\u001b[38;5;241m.\u001b[39mrender())\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#create first snapshot\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m first_snapshot \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mget_snapshot()\n",
      "Cell \u001b[1;32mIn[17], line 54\u001b[0m, in \u001b[0;36mWithSnapshots.get_snapshot\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m:returns: environment state that can be loaded with load_snapshot \u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03mSnapshots guarantee same env behaviour each time they are loaded.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose() \u001b[38;5;66;03m#close popup windows since we can't pickle them\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m x \u001b[38;5;241m=\u001b[39m copy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dumps(PickleableSurface(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"initial_state:\")\n",
    "\n",
    "plt.imshow(env.render())\n",
    "\n",
    "#create first snapshot\n",
    "first_snapshot = env.get_snapshot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play without making snapshots (faster)\n",
    "while True:\n",
    "    is_done = env.step(env.action_space.sample())[2]\n",
    "    if is_done: \n",
    "        print(\"Whoops! We died!\")\n",
    "        break\n",
    "        \n",
    "print(\"final state:\")\n",
    "plt.imshow(env.render())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload initial state from created first snapshot\n",
    "env.load_snapshot(first_snapshot)\n",
    "\n",
    "print(\"\\n\\nAfter loading snapshot\")\n",
    "plt.imshow(env.render())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get outcome (snapshot, observation, reward, is_done, info)\n",
    "res = env.get_result(snap0,env.action_space.sample())\n",
    "\n",
    "snap1, observation, reward = res[:3]\n",
    "\n",
    "#second step\n",
    "res2 = env.get_result(snap1,env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS: Monte-Carlo tree search\n",
    "\n",
    "In this section, we'll implement the vanilla MCTS algorithm with UCB1-based node selection.\n",
    "\n",
    "We will start by implementing the `Node` class - a simple class that acts like MCTS node and supports some of the MCTS algorithm steps.\n",
    "\n",
    "This MCTS implementation makes some assumptions about the environment, you can find those _in the notes section at the end of the notebook_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(env,WithSnapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\" a tree node for MCTS \"\"\"\n",
    "    \n",
    "    #metadata:\n",
    "    parent = None          #parent Node\n",
    "    value_sum = 0.         #sum of state values from all visits (numerator)\n",
    "    times_visited = 0      #counter of visits (denominator)\n",
    "\n",
    "    \n",
    "    def __init__(self,parent,action,):\n",
    "        \"\"\"\n",
    "        Creates and empty node with no children.\n",
    "        Does so by commiting an action and recording outcome.\n",
    "        \n",
    "        :param parent: parent Node\n",
    "        :param action: action to commit from parent Node\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.parent = parent\n",
    "        self.action = action        \n",
    "        self.children = set()       #set of child nodes\n",
    "\n",
    "        #get action outcome and save it\n",
    "        res = env.get_result(parent.snapshot,action)\n",
    "        self.snapshot,self.observation,self.immediate_reward,self.is_done,_ = res\n",
    "        \n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return len(self.children)==0\n",
    "    \n",
    "    def is_root(self):\n",
    "        return self.parent is None\n",
    "    \n",
    "    def get_mean_value(self):\n",
    "        return self.value_sum / self.times_visited if self.times_visited !=0 else 0\n",
    "    \n",
    "    def ucb_score(self,scale=10,max_value=1e100):\n",
    "        \"\"\"\n",
    "        Computes ucb1 upper bound using current value and visit counts for node and it's parent.\n",
    "        \n",
    "        :param scale: Multiplies upper bound by that. From hoeffding inequality, assumes reward range to be [0,scale].\n",
    "        :param max_value: a value that represents infinity (for unvisited nodes)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.times_visited == 0:\n",
    "            return max_value\n",
    "        \n",
    "        #compute ucb-1 additive component (to be added to mean value) (exploration)\n",
    "        #hint: you can use self.parent.times_visited for N times node was considered,\n",
    "        # and self.times_visited for n times it was visited\n",
    "        \n",
    "        U = <your code here>\n",
    "        \n",
    "        return self.get_mean_value() + scale*U\n",
    "    \n",
    "    \n",
    "    #MCTS steps\n",
    "    \n",
    "    def select_best_leaf(self):\n",
    "        \"\"\"\n",
    "        Picks the leaf with highest priority to expand\n",
    "        Does so by recursively picking nodes with best UCB-1 score until it reaches the leaf.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.is_leaf():\n",
    "            return self\n",
    "        \n",
    "        children = self.children\n",
    "        \n",
    "        best_child = <select best child node in terms of node.ucb_score()>\n",
    "        \n",
    "        return best_child.select_best_leaf()\n",
    "    \n",
    "    def expand(self):\n",
    "        \"\"\"\n",
    "        Expands the current node by creating all possible child nodes.\n",
    "        Then returns one of those children.\n",
    "        \"\"\"\n",
    "        \n",
    "        assert not self.is_done, \"can't expand from terminal state\"\n",
    "\n",
    "        for action in range(n_actions):\n",
    "            self.children.add(Node(self,action))\n",
    "        \n",
    "        return self.select_best_leaf()\n",
    "    \n",
    "    def rollout(self,t_max=10**4):\n",
    "        \"\"\"\n",
    "        Play the game from this state to the end (done) or for t_max steps.\n",
    "        \n",
    "        On each step, pick action at random (hint: env.action_space.sample()).\n",
    "        \n",
    "        Compute sum of rewards from current state till \n",
    "        Note 1: use env.action_space.sample() for random action\n",
    "        Note 2: if node is terminal (self.is_done is True), just return 0\n",
    "        \n",
    "        \"\"\"\n",
    "            \n",
    "        #set env into the appropriate state\n",
    "        env.load_snapshot(self.snapshot)\n",
    "        obs = self.observation\n",
    "        is_done = self.is_done\n",
    "        \n",
    "        totalRew = 0\n",
    "        \n",
    "        #<your code here - rollout and compute reward>\n",
    "\n",
    "        return rollout_reward\n",
    "    \n",
    "    def propagate(self,child_value):\n",
    "        \"\"\"\n",
    "        Uses child value (sum of rewards) to update parents recursively.\n",
    "        \"\"\"\n",
    "        #compute node value\n",
    "        my_value = \n",
    "        \n",
    "        #update value_sum and times_visited\n",
    "        self.value_sum+=my_value\n",
    "        self.times_visited+=1\n",
    "        \n",
    "        #propagate upwards\n",
    "        if not self.is_root():\n",
    "            self.parent.propagate(my_value)\n",
    "        \n",
    "    def safe_delete(self):\n",
    "        \"\"\"safe delete to prevent memory leak in some python versions\"\"\"\n",
    "        del self.parent\n",
    "        for child in self.children:\n",
    "            child.safe_delete()\n",
    "            del child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Root(Node):\n",
    "    def __init__(self,snapshot,observation):\n",
    "        \"\"\"\n",
    "        creates special node that acts like tree root\n",
    "        :snapshot: snapshot (from env.get_snapshot) to start planning from\n",
    "        :observation: last environment observation\n",
    "        \"\"\"\n",
    "        \n",
    "        self.parent = self.action = None\n",
    "        self.children = set()       #set of child nodes\n",
    "        \n",
    "        #root: load snapshot and observation\n",
    "        self.snapshot = snapshot\n",
    "        self.observation = observation\n",
    "        self.immediate_reward = 0\n",
    "        self.is_done=False\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_node(node):\n",
    "        \"\"\"initializes node as root\"\"\"\n",
    "        root = Root(node.snapshot,node.observation)\n",
    "        #copy data\n",
    "        copied_fields = [\"value_sum\",\"times_visited\",\"children\",\"is_done\"]\n",
    "        for field in copied_fields:\n",
    "            setattr(root,field,getattr(node,field))\n",
    "        return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main MCTS loop (4 pts)\n",
    "\n",
    "With all we implemented, MCTS boils down to a trivial piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_mcts(root,n_iters=10):\n",
    "    \"\"\"\n",
    "    builds tree with monte-carlo tree search for n_iters iterations\n",
    "    :param root: tree node to plan from\n",
    "    :param n_iters: how many select-expand-simulate-propagete loops to make\n",
    "    \"\"\"\n",
    "    for _ in range(n_iters):\n",
    "\n",
    "        node = <select best leaf>\n",
    "\n",
    "        if node.is_done:\n",
    "            node.propagate(0)\n",
    "\n",
    "        else: #node is not terminal\n",
    "            <expand-rollout(simluate)-propagate loop>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan and execute (3 pts)\n",
    "In this section, we use the MCTS implementation to find optimal policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_observation = env.reset()\n",
    "root_snapshot = env.get_snapshot()\n",
    "root = Root(root_snapshot,root_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plan from root:\n",
    "plan_mcts(root,n_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from itertools import count\n",
    "from gym.wrappers import Monitor\n",
    "\n",
    "total_reward = 0                #sum of rewards\n",
    "test_env = loads(root_snapshot) #env used to show progress\n",
    "\n",
    "for i in count():\n",
    "    \n",
    "    #get best child\n",
    "    best_child = <select child with highest mean reward>\n",
    "    \n",
    "    #take action\n",
    "    s,r,done,_ = test_env.step(best_child.action)\n",
    "    \n",
    "    #show image\n",
    "    clear_output(True)\n",
    "    plt.title(\"step %i\"%i)\n",
    "    plt.imshow(test_env.render('rgb_array'))\n",
    "    plt.show()\n",
    "\n",
    "    total_reward += r\n",
    "    if done:\n",
    "        print(\"Finished with reward = \",total_reward)\n",
    "        break\n",
    "    \n",
    "    #discard unrealized part of the tree [because not every child matters :(]\n",
    "    for child in root.children:\n",
    "        if child != best_child:\n",
    "            child.safe_delete()\n",
    "\n",
    "    #declare best child a new root\n",
    "    root = Root.from_node(best_child)\n",
    "    \n",
    "    assert not root.is_leaf(), \"We ran out of tree! Need more planning! Try growing tree right inside the loop.\"\n",
    "    \n",
    "    #you may want to expand tree here\n",
    "    #<your code here>\n",
    "    #optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
