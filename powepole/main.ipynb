{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# !pip install wheel==0.38.4\n",
    "# !pip install setuptools==65\n",
    "# !pip install gym==0.21\n",
    "# !pip install torchrl\n",
    "# pip install stable-baselines3[extra]\n",
    "# !pip install torchvision\n",
    "# !pip install gym==0.21\n",
    "# !pip install --upgrade ipykernel\n",
    "# !pip install matplotlib\n",
    "# !pip install gym[atari,accept-rom-license]==0.21.0\n",
    "# !pip install joblib\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# hide imports\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchrl\n",
    "import torch\n",
    "import logging\n",
    "import tqdm\n",
    "from torchrl.envs import *\n",
    "from torchrl.envs.libs.gym import *\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "from multiprocessing import Pool\n",
    "from agent import Agent\n",
    "from constants import *\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random_seed = 21\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Версия gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Действие игры происходит в среде gym \"Assault\"\n",
    "\n",
    "Давайте поменяем нашу среду для лучшего обучения.\n",
    "\n",
    "Во-первых сделаем resize картинки до размера 64x64 (W = 64, H = 64).\n",
    "Во-вторых переведем ее в черно-белое изображение.\n",
    "В-третьих Добавим frameskip в 4 кадра.\n",
    "\n",
    "Для этого воспользуемся классом TransformedEnv из torchrl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_actions = 2\n"
     ]
    }
   ],
   "source": [
    "#hide changing environment\n",
    "\n",
    "_env = gym.make(\"CartPole-v1\").env\n",
    "\n",
    "n_actions = _env.action_space.n # see more info in actions.txt\n",
    "\n",
    "print(\"n_actions =\", n_actions)\n",
    "\n",
    "from torchrl.envs import *\n",
    "from torchrl.envs.libs.gym import *\n",
    "\n",
    "\n",
    "env = TransformedEnv(\n",
    "    GymEnv(\"CartPole-v1\", from_pixels=True),\n",
    "    Compose(\n",
    "        ToTensorImage(in_keys=[\"pixels\"], out_keys=[\"pixels_trsf\"]),\n",
    "        Resize(in_keys=[\"pixels_trsf\"], w=W, h=H),\n",
    "        GrayScale(in_keys=[\"pixels_trsf\"]),\n",
    "        FrameSkipTransform(1), \n",
    "        ExcludeTransform(\"pixels\")\n",
    "    ),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим state это TensorDict, состоящий из нескольких параметров, в том числе done, pixels_trsf (Измененное изображение), terminated, truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        pixels_trsf: Tensor(shape=torch.Size([1, 84, 84]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим, как выглядит изменная среда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 84, 84])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2273d6d9990>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGgCAYAAADsNrNZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhsUlEQVR4nO3de3DU1f3/8dfmtomE3ZgIu0lNMFraoEDVoGGBtqOkZqhaKdGqgwWVkaoRDfFGWsGiYlA7ihcu1bGoo0hlqijOCIOxxmEMtyjWGwErNamwi7ZmN6BsMHu+f/Tn/lwShc3tZMPzMXNm+JzPZd+cCfvi5HM+uw5jjBEAAH0syXYBAICjEwEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCi1wJo8eLFOuGEE5Senq6SkhJt3ry5t14KAJCAHL3xWXB//etfNW3aNC1btkwlJSVatGiRVq1apcbGRg0dOvR7z41EItq9e7cGDx4sh8PR06UBAHqZMUatra3Ky8tTUtL3zHNMLzjzzDNNRUVFdLu9vd3k5eWZmpqaw57b3NxsJNFoNBotwVtzc/P3vt+nqIe1tbWpoaFB1dXV0b6kpCSVlpaqvr6+w/HhcFjhcDi6bf7fhKy5uVkul6unywMA9LJQKKT8/HwNHjz4e4/r8QD6/PPP1d7eLo/HE9Pv8Xi0ffv2DsfX1NRo/vz5HfpdLhcBBAAJ7HC3UayvgquurlYwGIy25uZm2yUBAPpAj8+AjjvuOCUnJysQCMT0BwIBeb3eDsc7nU45nc6eLgMA0M/1+AwoLS1NxcXFqq2tjfZFIhHV1tbK5/P19MsBABJUj8+AJKmqqkrTp0/XmDFjdOaZZ2rRokXav3+/rrjiit54OQBAAuqVALr44ov12Wefad68efL7/Tr11FO1du3aDgsTAABHr155ELU7QqGQ3G63gsEgq+AAIAEd6fu49VVwAICjEwEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgRdwB9MYbb+j8889XXl6eHA6HVq9eHbPfGKN58+YpNzdXGRkZKi0t1c6dO3uqXgDAABF3AO3fv18/+clPtHjx4k7333vvvXrooYe0bNkybdq0SYMGDVJZWZkOHDjQ7WIBAANHSrwnTJo0SZMmTep0nzFGixYt0m233aYLLrhAkvTUU0/J4/Fo9erVuuSSS7pXLQBgwOjRe0C7du2S3+9XaWlptM/tdqukpET19fWdnhMOhxUKhWIaAGDg69EA8vv9kiSPxxPT7/F4ovsOVVNTI7fbHW35+fk9WRIAoJ+yvgquurpawWAw2pqbm22XBADoAz0aQF6vV5IUCARi+gOBQHTfoZxOp1wuV0wDAAx8PRpAhYWF8nq9qq2tjfaFQiFt2rRJPp+vJ18KAJDg4l4Ft2/fPn300UfR7V27dmnbtm3Kzs5WQUGBKisrddddd2n48OEqLCzU3LlzlZeXp8mTJ/dk3QCABBd3AG3dulVnnXVWdLuqqkqSNH36dD3xxBO65ZZbtH//fs2cOVMtLS2aMGGC1q5dq/T09J6rGgCQ8BzGGGO7iG8LhUJyu90KBoPcDwKABHSk7+PWV8EBAI5OBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVcQVQTU2NzjjjDA0ePFhDhw7V5MmT1djYGHPMgQMHVFFRoZycHGVmZqq8vFyBQKBHiwYAJL64Aqiurk4VFRXauHGj1q9fr4MHD+qcc87R/v37o8fMnj1ba9as0apVq1RXV6fdu3drypQpPV44ACCxOYwxpqsnf/bZZxo6dKjq6ur0s5/9TMFgUEOGDNGKFSt04YUXSpK2b9+uESNGqL6+XmPHjj3sNUOhkNxut4LBoFwuV1dLAwBYcqTv4926BxQMBiVJ2dnZkqSGhgYdPHhQpaWl0WOKiopUUFCg+vr6Tq8RDocVCoViGgBg4OtyAEUiEVVWVmr8+PEaOXKkJMnv9ystLU1ZWVkxx3o8Hvn9/k6vU1NTI7fbHW35+fldLQkAkEC6HEAVFRV67733tHLlym4VUF1drWAwGG3Nzc3duh4AIDGkdOWk6667Ti+//LLeeOMNHX/88dF+r9ertrY2tbS0xMyCAoGAvF5vp9dyOp1yOp1dKQMAkMDimgEZY3TdddfphRde0GuvvabCwsKY/cXFxUpNTVVtbW20r7GxUU1NTfL5fD1TMQBgQIhrBlRRUaEVK1boxRdf1ODBg6P3ddxutzIyMuR2uzVjxgxVVVUpOztbLpdLs2bNks/nO6IVcACAo0dcy7AdDken/cuXL9fll18u6X8Pot5444169tlnFQ6HVVZWpiVLlnznr+AOxTJsAEhsR/o+3q3ngHoDAQQAia1PngMCAKCrCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAAr4gqgpUuXavTo0XK5XHK5XPL5fHrllVei+w8cOKCKigrl5OQoMzNT5eXlCgQCPV40ACDxxRVAxx9/vBYuXKiGhgZt3bpVZ599ti644AK9//77kqTZs2drzZo1WrVqlerq6rR7925NmTKlVwoHACQ2hzHGdOcC2dnZuu+++3ThhRdqyJAhWrFihS688EJJ0vbt2zVixAjV19dr7NixR3S9UCgkt9utYDAol8vVndIAABYc6ft4l+8Btbe3a+XKldq/f798Pp8aGhp08OBBlZaWRo8pKipSQUGB6uvrv/M64XBYoVAopgEABr64A+jdd99VZmamnE6nrr76ar3wwgs6+eST5ff7lZaWpqysrJjjPR6P/H7/d16vpqZGbrc72vLz8+P+SwAAEk/cAfTjH/9Y27Zt06ZNm3TNNddo+vTp+uCDD7pcQHV1tYLBYLQ1Nzd3+VoAgMSREu8JaWlp+uEPfyhJKi4u1pYtW/Tggw/q4osvVltbm1paWmJmQYFAQF6v9zuv53Q65XQ6468cAJDQuv0cUCQSUTgcVnFxsVJTU1VbWxvd19jYqKamJvl8vu6+DABggIlrBlRdXa1JkyapoKBAra2tWrFihV5//XWtW7dObrdbM2bMUFVVlbKzs+VyuTRr1iz5fL4jXgEHADh6xBVAe/fu1bRp07Rnzx653W6NHj1a69at0y9+8QtJ0gMPPKCkpCSVl5crHA6rrKxMS5Ys6ZXCAQCJrdvPAfU0ngMCgMTW688BAQDQHQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwIu4vpAMQv0gkErP99ddfx2ynpqZ2OMfhcPRqTYBtzIAAAFYQQAAAKwggAIAVBBAAwAoWIQB94LPPPovZfvvtt2O2i4uLO5wzZMiQXq0JsI0ZEADACgIIAGAFAQQAsIJ7QEAfCIfDMdtffPHF9+4HjgbMgAAAVhBAAAArCCAAgBXcAwL6gDHme7eBoxEzIACAFQQQAMAKAggAYAUBBACwgkUIQB9g0QHQETMgAIAVBBAAwIpuBdDChQvlcDhUWVkZ7Ttw4IAqKiqUk5OjzMxMlZeXKxAIdLdOAMAA0+UA2rJli/785z9r9OjRMf2zZ8/WmjVrtGrVKtXV1Wn37t2aMmVKtwsFEtnXX38d0xwOR0xLSUnp0ICBrksBtG/fPk2dOlWPPfaYjj322Gh/MBjU448/rvvvv19nn322iouLtXz5cr355pvauHFjjxUNAEh8XQqgiooKnXvuuSotLY3pb2ho0MGDB2P6i4qKVFBQoPr6+k6vFQ6HFQqFYhoAYOCLe56/cuVKvfXWW9qyZUuHfX6/X2lpacrKyorp93g88vv9nV6vpqZG8+fPj7cMAECCi2sG1NzcrBtuuEHPPPOM0tPTe6SA6upqBYPBaGtubu6R6wIA+re4ZkANDQ3au3evTj/99Ghfe3u73njjDT3yyCNat26d2tra1NLSEjMLCgQC8nq9nV7T6XTK6XR2rXogQbS3t8dsOxyOmO3k5OS+LAfoF+IKoIkTJ+rdd9+N6bviiitUVFSkW2+9Vfn5+UpNTVVtba3Ky8slSY2NjWpqapLP5+u5qgEACS+uABo8eLBGjhwZ0zdo0CDl5ORE+2fMmKGqqiplZ2fL5XJp1qxZ8vl8Gjt2bM9VDQBIeD3+sMEDDzygpKQklZeXKxwOq6ysTEuWLOnplwEAJLhuB9Drr78es52enq7Fixdr8eLF3b00cNQ49J4QcDTgs+AAAFYQQAAAKwggAIAVfOIh0A9wDwhHI2ZAAAArCCAAgBUEEADACgIIAGAFixAACw5ddMAiBByNmAEBAKwggAAAVhBAAAAruAcE9AFjzPfu5x4QjkbMgAAAVhBAAAArCCAAgBUEEADAChYhAH3gcIsQgKMRMyAAgBUEEADACgIIAGAF94CAPtDe3m67BKDfYQYEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQ+iAn2gra0tZjspKel7t4GjAT/1AAArCCAAgBVxBdAf//hHORyOmFZUVBTdf+DAAVVUVCgnJ0eZmZkqLy9XIBDo8aIBAIkv7hnQKaecoj179kTbhg0bovtmz56tNWvWaNWqVaqrq9Pu3bs1ZcqUHi0YSESRSCSmJSUlHbYBA13cixBSUlLk9Xo79AeDQT3++ONasWKFzj77bEnS8uXLNWLECG3cuFFjx47tfrUAgAEj7v9m7dy5U3l5eTrxxBM1depUNTU1SZIaGhp08OBBlZaWRo8tKipSQUGB6uvrv/N64XBYoVAopgEABr64AqikpERPPPGE1q5dq6VLl2rXrl366U9/qtbWVvn9fqWlpSkrKyvmHI/HI7/f/53XrKmpkdvtjrb8/Pwu/UUAAIklrl/BTZo0Kfrn0aNHq6SkRMOGDdNzzz2njIyMLhVQXV2tqqqq6HYoFCKEAOAo0K07nVlZWfrRj36kjz76SF6vV21tbWppaYk5JhAIdHrP6BtOp1MulyumAUebQ1eXOhwO2yUBva5bAbRv3z7985//VG5uroqLi5Wamqra2tro/sbGRjU1Ncnn83W7UADAwBLXr+BuuukmnX/++Ro2bJh2796t22+/XcnJybr00kvldrs1Y8YMVVVVKTs7Wy6XS7NmzZLP52MFHACgg7gC6N///rcuvfRS/ec//9GQIUM0YcIEbdy4UUOGDJEkPfDAA0pKSlJ5ebnC4bDKysq0ZMmSXikcAJDYHMYYY7uIbwuFQnK73QoGg9wPwoCxdevWmO1vHl/4xjnnnNPhnMzMzF6tCegtR/o+zuPWAAArCCAAgBUEEADACr6QDrDg0Od8+PBRHI34qQcAWEEAAQCsIIAAAFYQQAAAK1iEAPSBfva8N9AvMAMCAFhBAAEArCCAAABWcA8I6AORSMR2CUC/wwwIAGAFAQQAsIIAAgBYQQABAKxgEQLQB3gQFeiIGRAAwAoCCABgBQEEALCCe0BAH+AeENARMyAAgBUEEADACgIIAGAF94CAHtbZ/Z6DBw/GbCcnJ8dsJyXxf0EcffipBwBYQQABAKwggAAAVhBAAAArWIQAxOGdd945or54Pffcc4c95sQTT+zQN2HChG6/NmALMyAAgBUEEADAirgD6NNPP9Vll12mnJwcZWRkaNSoUdq6dWt0vzFG8+bNU25urjIyMlRaWqqdO3f2aNEAgMQX1z2gL774QuPHj9dZZ52lV155RUOGDNHOnTt17LHHRo+599579dBDD+nJJ59UYWGh5s6dq7KyMn3wwQdKT0/v8b8A0JdWr17doW/+/Pkx24c+ZCpJM2bMiNn+9r8ZSXrkkUc6nLN///6Y7WnTpnU4Zty4cTHbPNCKRBJXAN1zzz3Kz8/X8uXLo32FhYXRPxtjtGjRIt1222264IILJElPPfWUPB6PVq9erUsuuaSHygYAJLq4/rv00ksvacyYMbrooos0dOhQnXbaaXrsscei+3ft2iW/36/S0tJon9vtVklJierr6zu9ZjgcVigUimkAgIEvrgD6+OOPtXTpUg0fPlzr1q3TNddco+uvv15PPvmkJMnv90uSPB5PzHkejye671A1NTVyu93Rlp+f35W/BwAgwcQVQJFIRKeffrruvvtunXbaaZo5c6auuuoqLVu2rMsFVFdXKxgMRltzc3OXrwUASBxx3QPKzc3VySefHNM3YsQI/e1vf5Mkeb1eSVIgEFBubm70mEAgoFNPPbXTazqdTjmdznjKAKzp7JOuD+2LRCIdjgmHwzHbX331Vcx2e3v7Ya/Lt6pioIlrBjR+/Hg1NjbG9O3YsUPDhg2T9L8FCV6vV7W1tdH9oVBImzZtks/n64FyAQADRVwzoNmzZ2vcuHG6++679Zvf/EabN2/Wo48+qkcffVSS5HA4VFlZqbvuukvDhw+PLsPOy8vT5MmTe6N+AECCiiuAzjjjDL3wwguqrq7WHXfcocLCQi1atEhTp06NHnPLLbdo//79mjlzplpaWjRhwgStXbuWZ4AAADHi/jDS8847T+edd9537nc4HLrjjjt0xx13dKuwTz75RIMHD+7WNYCe1tLScthjOrtXs2PHjpjtQ+97fv3114e9bmtra4e+f/3rXzHbPIiK/qCzn9XO8NMKALCCAAIAWEEAAQCs6LdfSDdo0CANGjTIdhlAjLS0tMMe09k9oDfffLPbr52amtqh79B/I9wDQn/Q2bNwneGnFQBgBQEEALCCAAIAWEEAAQCs6LeLEI477ji5XC7bZQAxjjnmGGuv3dmniQwZMiRmm0UI6A+O9AOm+WkFAFhBAAEArCCAAABW9Nt7QEB/1Nl9GLfb3SevbfP+E9AbmAEBAKwggAAAVhBAAAArCCAAgBUsQgDiMG3atA59EydO7JPXzsnJ6dDHg6dIZPz0AgCsIIAAAFYQQAAAK7gHBMQhLy/viPoAHB4zIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYEVcAXTCCSfI4XB0aBUVFZKkAwcOqKKiQjk5OcrMzFR5ebkCgUCvFA4ASGxxBdCWLVu0Z8+eaFu/fr0k6aKLLpIkzZ49W2vWrNGqVatUV1en3bt3a8qUKT1fNQAg4TmMMaarJ1dWVurll1/Wzp07FQqFNGTIEK1YsUIXXnihJGn79u0aMWKE6uvrNXbs2CO6ZigUktvtVjAYlMvl6mppAABLjvR9vMv3gNra2vT000/ryiuvlMPhUENDgw4ePKjS0tLoMUVFRSooKFB9ff13XiccDisUCsU0AMDA1+UAWr16tVpaWnT55ZdLkvx+v9LS0pSVlRVznMfjkd/v/87r1NTUyO12R1t+fn5XSwIAJJAuB9Djjz+uSZMmdfvLuKqrqxUMBqOtubm5W9cDACSGLn0j6ieffKJXX31Vzz//fLTP6/Wqra1NLS0tMbOgQCAgr9f7nddyOp1yOp1dKQMAkMC6NANavny5hg4dqnPPPTfaV1xcrNTUVNXW1kb7Ghsb1dTUJJ/P1/1KAQADStwzoEgkouXLl2v69OlKSfn/p7vdbs2YMUNVVVXKzs6Wy+XSrFmz5PP5jngFHADg6BF3AL366qtqamrSlVde2WHfAw88oKSkJJWXlyscDqusrExLlizpkUIBAANLt54D6g08BwQAia3XnwMCAKA7CCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAAr4gqg9vZ2zZ07V4WFhcrIyNBJJ52kO++8U8aY6DHGGM2bN0+5ubnKyMhQaWmpdu7c2eOFAwASW1wBdM8992jp0qV65JFH9OGHH+qee+7Rvffeq4cffjh6zL333quHHnpIy5Yt06ZNmzRo0CCVlZXpwIEDPV48ACBxOcy3py+Hcd5558nj8ejxxx+P9pWXlysjI0NPP/20jDHKy8vTjTfeqJtuukmSFAwG5fF49MQTT+iSSy457GuEQiG53W4Fg0G5XK4u/JUAADYd6ft4XDOgcePGqba2Vjt27JAkvfPOO9qwYYMmTZokSdq1a5f8fr9KS0uj57jdbpWUlKi+vr7Ta4bDYYVCoZgGABj4UuI5eM6cOQqFQioqKlJycrLa29u1YMECTZ06VZLk9/slSR6PJ+Y8j8cT3XeompoazZ8/vyu1AwASWFwzoOeee07PPPOMVqxYobfeektPPvmk/vSnP+nJJ5/scgHV1dUKBoPR1tzc3OVrAQASR1wzoJtvvllz5syJ3ssZNWqUPvnkE9XU1Gj69Onyer2SpEAgoNzc3Oh5gUBAp556aqfXdDqdcjqdXSwfAJCo4poBffnll0pKij0lOTlZkUhEklRYWCiv16va2tro/lAopE2bNsnn8/VAuQCAgSKuGdD555+vBQsWqKCgQKeccorefvtt3X///bryyislSQ6HQ5WVlbrrrrs0fPhwFRYWau7cucrLy9PkyZN7o34AQIKKK4AefvhhzZ07V9dee6327t2rvLw8/e53v9O8efOix9xyyy3av3+/Zs6cqZaWFk2YMEFr165Venp6jxcPAEhccT0H1Bd4DggAEluvPAcEAEBPIYAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALAirgdR+8I3jyXxtQwAkJi+ef8+3GOm/S6AWltbJUn5+fmWKwEAdEdra6vcbvd37u93n4QQiUS0e/duDR48WK2trcrPz1dzczOfitALQqEQ49uLGN/exfj2ru6MrzFGra2tysvL6/AB1t/W72ZASUlJOv744yX978NNJcnlcvED1osY397F+PYuxrd3dXV8v2/m8w0WIQAArCCAAABW9OsAcjqduv322/nG1F7C+PYuxrd3Mb69qy/Gt98tQgAAHB369QwIADBwEUAAACsIIACAFQQQAMAKAggAYEW/DaDFixfrhBNOUHp6ukpKSrR582bbJSWkmpoanXHGGRo8eLCGDh2qyZMnq7GxMeaYAwcOqKKiQjk5OcrMzFR5ebkCgYClihPXwoUL5XA4VFlZGe1jbLvv008/1WWXXaacnBxlZGRo1KhR2rp1a3S/MUbz5s1Tbm6uMjIyVFpaqp07d1qsOHG0t7dr7ty5KiwsVEZGhk466STdeeedMR8i2qvja/qhlStXmrS0NPOXv/zFvP/+++aqq64yWVlZJhAI2C4t4ZSVlZnly5eb9957z2zbts388pe/NAUFBWbfvn3RY66++mqTn59vamtrzdatW83YsWPNuHHjLFadeDZv3mxOOOEEM3r0aHPDDTdE+xnb7vnvf/9rhg0bZi6//HKzadMm8/HHH5t169aZjz76KHrMwoULjdvtNqtXrzbvvPOO+dWvfmUKCwvNV199ZbHyxLBgwQKTk5NjXn75ZbNr1y6zatUqk5mZaR588MHoMb05vv0ygM4880xTUVER3W5vbzd5eXmmpqbGYlUDw969e40kU1dXZ4wxpqWlxaSmpppVq1ZFj/nwww+NJFNfX2+rzITS2tpqhg8fbtavX29+/vOfRwOIse2+W2+91UyYMOE790ciEeP1es19990X7WtpaTFOp9M8++yzfVFiQjv33HPNlVdeGdM3ZcoUM3XqVGNM749vv/sVXFtbmxoaGlRaWhrtS0pKUmlpqerr6y1WNjAEg0FJUnZ2tiSpoaFBBw8ejBnvoqIiFRQUMN5HqKKiQueee27MGEqMbU946aWXNGbMGF100UUaOnSoTjvtND322GPR/bt27ZLf748ZY7fbrZKSEsb4CIwbN061tbXasWOHJOmdd97Rhg0bNGnSJEm9P7797tOwP//8c7W3t8vj8cT0ezwebd++3VJVA0MkElFlZaXGjx+vkSNHSpL8fr/S0tKUlZUVc6zH45Hf77dQZWJZuXKl3nrrLW3ZsqXDPsa2+z7++GMtXbpUVVVV+v3vf68tW7bo+uuvV1pamqZPnx4dx87eLxjjw5szZ45CoZCKioqUnJys9vZ2LViwQFOnTpWkXh/ffhdA6D0VFRV67733tGHDBtulDAjNzc264YYbtH79eqWnp9suZ0CKRCIaM2aM7r77bknSaaedpvfee0/Lli3T9OnTLVeX+J577jk988wzWrFihU455RRt27ZNlZWVysvL65Px7Xe/gjvuuOOUnJzcYaVQIBCQ1+u1VFXiu+666/Tyyy/r73//e/T7liTJ6/Wqra1NLS0tMccz3ofX0NCgvXv36vTTT1dKSopSUlJUV1enhx56SCkpKfJ4PIxtN+Xm5urkk0+O6RsxYoSampokKTqOvF90zc0336w5c+bokksu0ahRo/Tb3/5Ws2fPVk1NjaTeH99+F0BpaWkqLi5WbW1ttC8Siai2tlY+n89iZYnJGKPrrrtOL7zwgl577TUVFhbG7C8uLlZqamrMeDc2NqqpqYnxPoyJEyfq3Xff1bZt26JtzJgxmjp1avTPjG33jB8/vsNjAzt27NCwYcMkSYWFhfJ6vTFjHAqFtGnTJsb4CHz55ZcdvrE0OTlZkUhEUh+Mb7eXMfSClStXGqfTaZ544gnzwQcfmJkzZ5qsrCzj9/ttl5ZwrrnmGuN2u83rr79u9uzZE21ffvll9Jirr77aFBQUmNdee81s3brV+Hw+4/P5LFaduL69Cs4Yxra7Nm/ebFJSUsyCBQvMzp07zTPPPGOOOeYY8/TTT0ePWbhwocnKyjIvvvii+cc//mEuuOAClmEfoenTp5sf/OAH0WXYzz//vDnuuOPMLbfcEj2mN8e3XwaQMcY8/PDDpqCgwKSlpZkzzzzTbNy40XZJCUlSp2358uXRY7766itz7bXXmmOPPdYcc8wx5te//rXZs2ePvaIT2KEBxNh235o1a8zIkSON0+k0RUVF5tFHH43ZH4lEzNy5c43H4zFOp9NMnDjRNDY2Wqo2sYRCIXPDDTeYgoICk56ebk488UTzhz/8wYTD4egxvTm+fB8QAMCKfncPCABwdCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACv+D6zH7hPRZyP5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "print(state['pixels_trsf'].shape)\n",
    "\n",
    "plt.imshow(state['pixels_trsf'].cpu().permute(1, 2, 0), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем агента\n",
    "\n",
    "### Для обучения агента я использую:\n",
    "  * Нейронную сеть, состоящую из сверточных и полносвязных слоев. (Подробнее смотри файл network.py)\n",
    "  * Реплей с приоритетами (TensorDictReplayBuffer) размера SIZE = 20000.\n",
    "  * Optimizer - Adam\n",
    "  * Для пересчета в Q-формуле использую target_network, которую обновляю каждые 30000 фреймов.\n",
    "  \n",
    "Для подробностей см. файл agent.py\n",
    "Также есть возможность загрузки и сохранения агента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of layer after convolution layers 4624\n",
      "Size of layer after convolution layers 4624\n"
     ]
    }
   ],
   "source": [
    "# создаем агента\n",
    "agent = Agent(num_channels=NUM_CHANNELS, width=W, height=H, n_actions=n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим для наглядности графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#hide plot\n",
    "def plot(agent):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    plt.title('Rewards per frames')\n",
    "    plt.xlabel(\"Frames\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.plot(agent.frames, agent.reward_history, color='blue')\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.title('Loss per frames')\n",
    "    plt.xlabel(\"Frames\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(agent.frames, agent.loss_history, color='orange')\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.title('Rewards per last 100 sessions')\n",
    "    plt.xlabel(\"Sessions\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.plot(agent.reward_history[-100:], color='blue')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.title('Loss per last 100 sessions')\n",
    "    plt.xlabel(\"Sessions\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(agent.loss_history[-100:], color='orange')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Играем сессию и записываем в агента опыт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# hide session\n",
    "\n",
    "from tensordict import TensorDict\n",
    "\n",
    "def play_session(agent, t_max=(int)(1e5), epsilon=0):\n",
    "    env = TransformedEnv(\n",
    "    GymEnv(\"CartPole-v1\", from_pixels=True),\n",
    "    Compose(\n",
    "        ToTensorImage(in_keys=[\"pixels\"], out_keys=[\"pixels_trsf\"]),\n",
    "        Resize(in_keys=[\"pixels_trsf\"], w=W, h=H),\n",
    "        GrayScale(in_keys=[\"pixels_trsf\"]),\n",
    "        FrameSkipTransform(1), \n",
    "        ExcludeTransform(\"pixels\")\n",
    "    )).to(device)\n",
    "\n",
    "    total_reward = 0\n",
    "    state = env.reset()\n",
    "    \n",
    "    frames = 0\n",
    "    L = 0\n",
    "\n",
    "    for t in range(t_max):\n",
    "        action = agent.select_action(state['pixels_trsf'], epsilon=epsilon)\n",
    "\n",
    "        state['action'] = torch.zeros(n_actions)\n",
    "        state['action'][action] = 1\n",
    "\n",
    "        next_state = env.step(state)['next']\n",
    "\n",
    "        next_state['done'] = next_state['done'] + next_state['terminated'] + next_state['truncated']\n",
    "        next_state.pop('truncated', None)\n",
    "        next_state.pop('terminated', None)\n",
    "        state['next'] = next_state\n",
    "\n",
    "        _action = torch.tensor(action)\n",
    "        # _action[action] = 1\n",
    "\n",
    "        data = TensorDict({\n",
    "            \"state\" : state['pixels_trsf'],\n",
    "            \"action\" : np.asarray([np.asarray(_action)]),\n",
    "            \"reward\": [next_state['reward']],\n",
    "            \"next_state\" : next_state['pixels_trsf'],\n",
    "            \"done\" : [next_state['done']]\n",
    "            }, \n",
    "            batch_size=[]\n",
    "        )\n",
    "\n",
    "        agent.record_experience(data)\n",
    "\n",
    "        # loss = agent.compute_loss(state['pixels_trsf'], np.asarray([np.asarray(_action)]), [next_state['reward']], next_state['pixels_trsf'], [next_state['done']])\n",
    "\n",
    "        total_reward += next_state['reward']\n",
    "\n",
    "        state = next_state\n",
    "        \n",
    "        frames += 1\n",
    "\n",
    "        if next_state['done']:\n",
    "            break\n",
    "    \n",
    "    return total_reward, frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбираем будем ли тренироваться и загружаться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "training = True\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing (add random states to replay buffer)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 38/300 [00:11<01:17,  3.37it/s]"
     ]
    }
   ],
   "source": [
    "if training:\n",
    "    if loading:\n",
    "        agent.load()\n",
    "\n",
    "    agent.save()\n",
    "\n",
    "    print(\"preparing (add random states to replay buffer)\")\n",
    "    if not loading:\n",
    "        for i in tqdm.tqdm(range(300)):\n",
    "            play_session(agent, epsilon=1)\n",
    "    else:\n",
    "        for i in tqdm.tqdm(range(20)):\n",
    "            play_session(agent, epsilon=agent.epsilon)\n",
    "    \n",
    "    epoch = 0\n",
    "    while True:\n",
    "        rewards = np.asarray([])\n",
    "        count_frames = 0\n",
    "        for _ in tqdm.tqdm(range(10)):\n",
    "                rewards_for_session, cnt = play_session(agent, t_max=(int)(agent.t_max), epsilon=agent.epsilon)\n",
    "                rewards_for_session = np.asarray(torch.as_tensor(rewards_for_session).cpu())\n",
    "                rewards = np.concatenate([rewards, rewards_for_session])\n",
    "                count_frames += cnt\n",
    "        \n",
    "        agent.epsilon *= 0.996\n",
    "\n",
    "        # loss = agent.train(batch_size)\n",
    "        \n",
    "        Loss = agent.train(250)\n",
    "        agent.loss_history.append(Loss)\n",
    "        agent.reward_history.append(np.mean(rewards))\n",
    "        last_frames = 0\n",
    "        if len(agent.frames) != 0:\n",
    "            last_frames = agent.frames[-1]\n",
    "        agent.frames.append(last_frames + count_frames)\n",
    "        clear_output(True)\n",
    "        \n",
    "        plot(agent)\n",
    "        print(\"for frame = \", last_frames + count_frames, \", epsilon = \", agent.epsilon)\n",
    "\n",
    "\n",
    "        if agent.epsilon < 0.1:\n",
    "            agent.epsilon = 0.12\n",
    "        \n",
    "        agent.t_max *= 1.01\n",
    "        epoch += 1\n",
    "        agent.t_max = min(agent.t_max, (int)(4e4))\n",
    "\n",
    "        if epoch % 10 == 1:\n",
    "            agent.save()\n",
    "            print('saved successfully')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not training:\n",
    "    pass # lets see result!"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
