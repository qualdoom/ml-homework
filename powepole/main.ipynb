{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# !pip install wheel==0.38.4\n",
    "# !pip install setuptools==65\n",
    "# !pip install gym==0.21\n",
    "# !pip install torchrl\n",
    "# pip install stable-baselines3[extra]\n",
    "# !pip install torchvision\n",
    "# !pip install gym==0.21\n",
    "# !pip install --upgrade ipykernel\n",
    "# !pip install matplotlib\n",
    "# !pip install gym[atari,accept-rom-license]==0.21.0\n",
    "# !pip install joblib\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# hide imports\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchrl\n",
    "import torch\n",
    "import tqdm\n",
    "from torchrl.envs import *\n",
    "from torchrl.envs.libs.gym import *\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "from multiprocessing import Pool\n",
    "from agent import Agent\n",
    "from constants import *\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random_seed = 21\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Версия gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Действие игры происходит в среде gym \"Assault\"\n",
    "\n",
    "Давайте поменяем нашу среду для лучшего обучения.\n",
    "\n",
    "Во-первых сделаем resize картинки до размера 64x64 (W = 64, H = 64).\n",
    "Во-вторых переведем ее в черно-белое изображение.\n",
    "В-третьих Добавим frameskip в 4 кадра.\n",
    "\n",
    "Для этого воспользуемся классом TransformedEnv из torchrl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_actions = 2\n"
     ]
    }
   ],
   "source": [
    "#hide changing environment\n",
    "\n",
    "_env = gym.make(\"CartPole-v1\").env\n",
    "\n",
    "n_actions = _env.action_space.n # see more info in actions.txt\n",
    "\n",
    "print(\"n_actions =\", n_actions)\n",
    "\n",
    "from torchrl.envs import *\n",
    "from torchrl.envs.libs.gym import *\n",
    "\n",
    "\n",
    "env = TransformedEnv(\n",
    "    GymEnv(\"CartPole-v1\", from_pixels=True),\n",
    "    Compose(\n",
    "        ToTensorImage(in_keys=[\"pixels\"], out_keys=[\"pixels_trsf\"]),\n",
    "        Resize(in_keys=[\"pixels_trsf\"], w=W, h=H),\n",
    "        GrayScale(in_keys=[\"pixels_trsf\"]),\n",
    "        FrameSkipTransform(1), \n",
    "        ExcludeTransform(\"pixels\")\n",
    "    ),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим state это TensorDict, состоящий из нескольких параметров, в том числе done, pixels_trsf (Измененное изображение), terminated, truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        pixels_trsf: Tensor(shape=torch.Size([1, 84, 84]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим, как выглядит изменная среда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 84, 84])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15372add930>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "print(state['pixels_trsf'].shape)\n",
    "\n",
    "plt.imshow(state['pixels_trsf'].cpu().permute(1, 2, 0), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем агента\n",
    "\n",
    "### Для обучения агента я использую:\n",
    "  * Нейронную сеть, состоящую из сверточных и полносвязных слоев. (Подробнее смотри файл network.py)\n",
    "  * Реплей с приоритетами (TensorDictReplayBuffer) размера SIZE = 20000.\n",
    "  * Optimizer - Adam\n",
    "  * Для пересчета в Q-формуле использую target_network, которую обновляю каждые 30000 фреймов.\n",
    "  \n",
    "Для подробностей см. файл agent.py\n",
    "Также есть возможность загрузки и сохранения агента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of layer after convolution layers 784\n",
      "Size of layer after convolution layers 784\n"
     ]
    }
   ],
   "source": [
    "# создаем агента\n",
    "agent = Agent(num_channels=NUM_CHANNELS, width=W, height=H, n_actions=n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим для наглядности графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#hide plot\n",
    "def plot(agent):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    plt.title('Rewards per frames')\n",
    "    plt.xlabel(\"Frames\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.plot(agent.frames, agent.reward_history, color='blue')\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.title('Loss per frames')\n",
    "    plt.xlabel(\"Frames\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(agent.frames, agent.loss_history, color='orange')\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.title('Rewards per last 100 sessions')\n",
    "    plt.xlabel(\"Sessions\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.plot(agent.reward_history[-100:], color='blue')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.title('Loss per last 100 sessions')\n",
    "    plt.xlabel(\"Sessions\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(agent.loss_history[-100:], color='orange')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Играем сессию и записываем в агента опыт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# hide session\n",
    "def play_session(agent, t_max=(int)(1e5), epsilon=0):\n",
    "    env = TransformedEnv(\n",
    "    GymEnv(\"CartPole-v1\", from_pixels=True),\n",
    "    Compose(\n",
    "        ToTensorImage(in_keys=[\"pixels\"], out_keys=[\"pixels_trsf\"]),\n",
    "        Resize(in_keys=[\"pixels_trsf\"], w=W, h=H),\n",
    "        GrayScale(in_keys=[\"pixels_trsf\"]),\n",
    "        FrameSkipTransform(1), \n",
    "        ExcludeTransform(\"pixels\")\n",
    "    )).to(device)\n",
    "\n",
    "    total_reward = 0\n",
    "    state = env.reset()\n",
    "    \n",
    "    frames = 0\n",
    "    L = 0\n",
    "\n",
    "    for t in range(t_max):\n",
    "        action = agent.select_action(state['pixels_trsf'], epsilon=epsilon)\n",
    "\n",
    "        state['action'] = torch.zeros(n_actions)\n",
    "        state['action'][action] = 1\n",
    "\n",
    "        next_state = env.step(state)['next']\n",
    "\n",
    "        next_state['done'] = next_state['done'] + next_state['terminated'] + next_state['truncated']\n",
    "        next_state.pop('truncated', None)\n",
    "        next_state.pop('terminated', None)\n",
    "        state['next'] = next_state\n",
    "\n",
    "        _action = torch.zeros(n_actions)\n",
    "        _action[action] = 1\n",
    "        print(_action)\n",
    "        print(state)\n",
    "        print(next_state)\n",
    "\n",
    "\n",
    "        agent.optimizer.zero_grad()\n",
    "        print(agent.compute_loss([state['pixels_trsf']], np.asarray([_action]), [next_state['reward']], [next_state['pixels_trsf']], [next_state['done']]))\n",
    "        loss = agent.compute_loss([state['pixels_trsf']], np.asarray([_action]), [next_state['reward']], [next_state['pixels_trsf']], [next_state['done']])\n",
    "\n",
    "        value = loss.detach()\n",
    "        L += value\n",
    "\n",
    "        loss.backward()\n",
    "        agent.optimizer.step()\n",
    "\n",
    "\n",
    "        total_reward += next_state['reward']\n",
    "\n",
    "        state = next_state\n",
    "        \n",
    "        frames += 1\n",
    "\n",
    "        if next_state['done']:\n",
    "            break\n",
    "    \n",
    "    return total_reward, frames, L / frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбираем будем ли тренироваться и загружаться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "training = True\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing (add random states to replay buffer)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0.])\n",
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                pixels_trsf: Tensor(shape=torch.Size([1, 84, 84]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        pixels_trsf: Tensor(shape=torch.Size([1, 84, 84]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        pixels_trsf: Tensor(shape=torch.Size([1, 84, 84]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m loading:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m300\u001b[39m)):\n\u001b[1;32m---> 10\u001b[0m         \u001b[43mplay_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m)):\n",
      "Cell \u001b[1;32mIn[9], line 40\u001b[0m, in \u001b[0;36mplay_session\u001b[1;34m(agent, t_max, epsilon)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(next_state)\n\u001b[0;32m     39\u001b[0m agent\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(agent\u001b[38;5;241m.\u001b[39mcompute_loss([state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixels_trsf\u001b[39m\u001b[38;5;124m'\u001b[39m]], \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_action\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, [next_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m]], [next_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixels_trsf\u001b[39m\u001b[38;5;124m'\u001b[39m]], [next_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m]]))\n\u001b[0;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mcompute_loss([state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixels_trsf\u001b[39m\u001b[38;5;124m'\u001b[39m]], np\u001b[38;5;241m.\u001b[39masarray([_action]), [next_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m]], [next_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixels_trsf\u001b[39m\u001b[38;5;124m'\u001b[39m]], [next_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     43\u001b[0m value \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "if training:\n",
    "    if loading:\n",
    "        agent.load()\n",
    "\n",
    "    agent.save()\n",
    "\n",
    "    print(\"preparing (add random states to replay buffer)\")\n",
    "    if not loading:\n",
    "        for i in tqdm.tqdm(range(300)):\n",
    "            play_session(agent, epsilon=1)\n",
    "    else:\n",
    "        for i in tqdm.tqdm(range(20)):\n",
    "            play_session(agent, epsilon=agent.epsilon)\n",
    "    \n",
    "    epoch = 0\n",
    "    while True:\n",
    "        rewards_for_session, count_frames, Loss = play_session(agent, t_max=(int)(agent.t_max), epsilon=agent.epsilon)\n",
    "        rewards_for_session = np.asarray(torch.as_tensor(rewards_for_session).cpu())\n",
    "        \n",
    "        agent.epsilon *= 0.996\n",
    "\n",
    "        # loss = agent.train(batch_size)\n",
    "        agent.loss_history.append(Loss)\n",
    "        agent.reward_history.append(np.mean(rewards_for_session))\n",
    "        last_frames = 0\n",
    "        if len(agent.frames) != 0:\n",
    "            last_frames = agent.frames[-1]\n",
    "        agent.frames.append(last_frames + count_frames)\n",
    "        clear_output(True)\n",
    "        \n",
    "        plot(agent)\n",
    "        print(\"for frame = \", last_frames + count_frames, \", epsilon = \", agent.epsilon)\n",
    "\n",
    "\n",
    "        if agent.epsilon < 0.1:\n",
    "            agent.epsilon = 0.12\n",
    "        \n",
    "        agent.t_max *= 1.01\n",
    "        epoch += 1\n",
    "        agent.t_max = min(agent.t_max, (int)(4e4))\n",
    "\n",
    "        if epoch % 10 == 1:\n",
    "            agent.save()\n",
    "            print('saved successfully')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not training:\n",
    "    pass # lets see result!"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
